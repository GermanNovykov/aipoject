{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_29120\\109452782.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  hearts['Cholesterol'].replace(0, chol_median, inplace=True)\n",
      "C:\\Users\\germa\\AppData\\Local\\Temp\\ipykernel_29120\\109452782.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  hearts['RestingBP'].replace(0, resting_median, inplace=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 45\u001b[0m\n\u001b[0;32m     40\u001b[0m y \u001b[38;5;241m=\u001b[39m hearts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeartDisease\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# # ENCODE X\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m encoder \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mOrdinalEncoder(cols\u001b[38;5;241m=\u001b[39m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m)\n\u001b[0;32m     46\u001b[0m X_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# # DATA SPLICING (TEST AND TRAIN)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, accuracy_score\n",
    "import seaborn as sns\n",
    "import category_encoders as ce \n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# TRAINING PART\n",
    "# IMPORT CSV\n",
    "hearts = pd.read_csv('train_heart.csv', sep=',')\n",
    "# FILTER VALUES\n",
    "chol_median = hearts.loc[hearts['Cholesterol'] != 0, 'Cholesterol'].median()\n",
    "hearts['Cholesterol'].replace(0, chol_median, inplace=True)\n",
    "\n",
    "resting_median = hearts.loc[hearts['RestingBP'] != 0, 'RestingBP'].median()\n",
    "hearts['RestingBP'].replace(0, resting_median, inplace=True)\n",
    "\n",
    "\n",
    "# # DROP UNNECESSARY COLS AND FIND y\n",
    "X = hearts.copy()\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "ordinal_encoder  = ce.OrdinalEncoder(cols=categorical_columns)\n",
    "features_encoded  = ordinal_encoder.fit_transform(X, axis=1)\n",
    "X = X.drop(['id', 'HeartDisease'], axis=1)\n",
    "poly_features_transformer = PolynomialFeatures(degree=2, include_bias=False)\n",
    "features_poly = poly_features_transformer.fit_transform(features_encoded)\n",
    "polynomial_feature_names = poly_features_transformer.get_feature_names_out(input_features=ordinal_encoder.get_feature_names_out())\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X = standard_scaler.fit_transform(features_poly)\n",
    "\n",
    "\n",
    "y = hearts['HeartDisease']\n",
    "\n",
    "\n",
    "\n",
    "# # ENCODE X\n",
    "encoder = ce.OrdinalEncoder(cols=X.columns)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# # DATA SPLICING (TEST AND TRAIN)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)\n",
    "\n",
    "# # FIT MODEL\n",
    "\n",
    "\n",
    "\n",
    "# Decision Tree Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# Decision Tree Grid Search Setup\n",
    "dt_grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Conduct Grid Search\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Optimal Decision Tree Estimator\n",
    "optimal_dt = dt_grid_search.best_estimator_\n",
    "y_pred = optimal_dt.predict(X_test)\n",
    "# # Calculating the accuracy\n",
    "accuracy_ada = accuracy_score(y_test, y_pred)\n",
    "print(f'RandomForest Accuracy: {accuracy_ada}')\n",
    "ada_boost_classifier = AdaBoostClassifier(estimator=optimal_dt)\n",
    "ada_boost_classifier.fit(X_train, y_train)\n",
    "y_pred = ada_boost_classifier.predict(X_test)\n",
    "# # Calculating the accuracy\n",
    "accuracy_ada = accuracy_score(y_test, y_pred)\n",
    "print(f'AdaBoost Decision Tree Accuracy: {accuracy_ada}')\n",
    "\n",
    "\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualizing the Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted No', 'Predicted Yes'], yticklabels=['Actual No', 'Actual Yes'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n",
    "# TESTING PART\n",
    "# IMPORT CSV\n",
    "test = pd.read_csv('test_heart.csv', sep=',')\n",
    "#FILTER VALUES\n",
    "chol_median = test.loc[test['Cholesterol'] != 0, 'Cholesterol'].median()\n",
    "test['Cholesterol'].replace(0, chol_median, inplace=True)\n",
    "\n",
    "resting_median = test.loc[test['RestingBP'] != 0, 'RestingBP'].median()\n",
    "test['RestingBP'].replace(0, resting_median, inplace=True)\n",
    "\n",
    "X_new = test.drop(['id'], axis=1)\n",
    "\n",
    "# # ENCODE X\n",
    "X_new_encoded = encoder.transform(X_new)\n",
    "\n",
    "# # PREDICT AND PUT INTO PANDAS DATAFRAME\n",
    "predictions = optimal_dt.predict(X_new_encoded)\n",
    "# Round up the predictions to 1 or 0\n",
    "rounded_predictions = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "id_to_prediction_df = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'HeartDisease': rounded_predictions\n",
    "})\n",
    "\n",
    "# # OUTPUT VIA CSV\n",
    "file_name = './submissiontest.csv'\n",
    "id_to_prediction_df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"File saved as {file_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
